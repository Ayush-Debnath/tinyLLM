{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Ayush-Debnath/tinyLLM/blob/main/tokenizer.ipynb",
      "authorship_tag": "ABX9TyMD1P3H9+n20QAhjyuh4B99",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush-Debnath/tinyLLM/blob/main/tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><i><h1>BUILDING A LLM</H1>from sctratch.....</i></b>"
      ],
      "metadata": {
        "id": "i2QdfoiDTcDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<i><H3>Data: The Verdict</h3></i> <br>\n",
        "loctaion: /content/drive/MyDrive/LLMDATA/the-verdict.txt"
      ],
      "metadata": {
        "id": "KaaJAQotal3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><i>Tokenizer</i></h3>\n",
        "\n",
        "<i>Step 1:</i> Splitting the test in individual words and subword tokens.<br>\n",
        "<i>Step 2:</i> Convert tokens into token IDs<br>\n",
        "<i>Step 3:</i> Encode token IDs into vector representations"
      ],
      "metadata": {
        "id": "ss4ao4ysT5fF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPzvYrS0S0zX",
        "outputId": "fb43b2fc-1703-477f-aa80-8b68d408dcb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of characters: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/LLMDATA/the-verdict.txt\", \"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text=f.read()\n",
        "print(\"total number of characters:\", len(raw_text))\n",
        "print(raw_text[:99])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "xebvCJBNS_Cz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h10>Preprocessing"
      ],
      "metadata": {
        "id": "OG-zuANRfVz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed=re.split(r'([,.:;?_!\"()\\']|--|\\s)',raw_text)\n",
        "preprocessed=[item.strip() for item in preprocessed if item.strip()]\n",
        "print(preprocessed[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37uERpCES-_Z",
        "outputId": "ee7a3bcf-4622-46bd-ef5d-9094774964a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT_zsJgQS-85",
        "outputId": "57c9fffe-54c7-4003-c154-04d739d7416c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words=sorted(set(preprocessed))\n",
        "print(\"vocab size: \",len(all_words))"
      ],
      "metadata": {
        "id": "vVQWNpDiS-53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fcb35ad-ff5a-44ab-bf8c-c50ade9ec5db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size:  1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab={token: integer for integer,token in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "ozRx-Q0wS-0M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i>=50:\n",
        "    break"
      ],
      "metadata": {
        "id": "NosTn40wS-xI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "45a138c2-b045-4a83-c18b-bf3f3a3445ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "  def __init__(self,vocab):\n",
        "    self.str_to_int=vocab\n",
        "    self.int_to_str={i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self,text):\n",
        "    # Reverted the incorrect ']' to ''' and removed the erroneous escape character\n",
        "    preprocessed=re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
        "\n",
        "    preprocessed=[\n",
        "        item.strip() for item in preprocessed if item.strip()\n",
        "    ]\n",
        "    ids=[self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self,ids):\n",
        "    text=\" \".join([self.int_to_str[i] for i in ids])\n",
        "    text=re.sub(r'\\s+([,.?!\"()\\'])',r'\\1',text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "TmpYECHzS-tq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=SimpleTokenizerV1(vocab)\n",
        "text=\"\"\"\"It's the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids=tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "id": "lQhlE8W3S-qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2000a6b2-108d-478e-8335-ec4efa4d46b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "id": "XO9-RLMfS-mu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a09c923d-7721-4b9b-b6ee-7b9ee1df9a63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding<br>\n",
        "<|unk|> --> unknown token<br>\n",
        "<|endoftext|> --> end of text token\n"
      ],
      "metadata": {
        "id": "lU1OjAjwduO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens=sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\",\"<|unk|>\"])"
      ],
      "metadata": {
        "id": "UZOxrrvlpXpK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab={token:integer for integer, token in enumerate(all_tokens)}"
      ],
      "metadata": {
        "id": "fkNcMsl_pXlW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab.items())"
      ],
      "metadata": {
        "id": "9UynLTYVpXgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b988e3ad-7336-4059-8aaa-5f8007883d49"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1132"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "kzXUROXhpXNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855bf2ec-4b3f-4fcb-b58a-d28f46a07d7f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV2:\n",
        "  def __init__(self,vocab):\n",
        "    self.str_to_int=vocab\n",
        "    self.int_to_str={i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self,text):\n",
        "    # Fix: Added missing closing parenthesis for the regex pattern\n",
        "    preprocessed=re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
        "    preprocessed=[item.strip() for item in preprocessed if item.strip()]\n",
        "    preprocessed=[\n",
        "        item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed\n",
        "    ]\n",
        "\n",
        "    ids=[self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self,ids):\n",
        "    text=\" \".join([self.int_to_str[i] for i in ids])\n",
        "    text=re.sub(r'\\s+([,.:;?!\"()\\'])',r'\\1',text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "1Y0zplMCpXIx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=SimpleTokenizerV2(vocab)\n",
        "text1=\"Hello, do you like some tea?\"\n",
        "text2=\"In the sunlit terraces of the palace.\"\n",
        "\n",
        "text=\"<|endoftext|> \".join((text1,text2))"
      ],
      "metadata": {
        "id": "gtm0HckkpW-w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wHQpPhpsdsRg",
        "outputId": "3f570246-a56b-4412-dbb0-1b8d701659ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, do you like some tea?<|endoftext|> In the sunlit terraces of the palace.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QIvr56KdsOT",
        "outputId": "12096e22-71f8-4b34-8dd0-fe7fc5525bae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1131,\n",
              " 5,\n",
              " 355,\n",
              " 1126,\n",
              " 628,\n",
              " 910,\n",
              " 975,\n",
              " 10,\n",
              " 1130,\n",
              " 55,\n",
              " 988,\n",
              " 956,\n",
              " 984,\n",
              " 722,\n",
              " 988,\n",
              " 1131,\n",
              " 7]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokenizer.encode(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuCcbgphdsJQ",
        "outputId": "b7e4942e-3a6b-4b16-8a71-87a901cbc3ee"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|unk|>, do you like some tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><i>BYTE PAIR ENCODING(BPE)</i></h3><br>\n",
        "It is a subword tokenization algorithm. Most common pair of consecutive bytes of data is replaced witha byte that does not occur in data."
      ],
      "metadata": {
        "id": "78nf1ZUfkSiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNN2jaxadsEq",
        "outputId": "bf186da1-3e34-4ebf-c537-510d68722b88"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version: \",importlib.metadata.version(\"tiktoken\") )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-9pIZpedsBS",
        "outputId": "9a35b88e-8750-4128-9de4-0cead2539ebf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version:  0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "nJXuwUf3dr9g"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=(\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "    \"of someunknownPlace\"\n",
        ")\n",
        "\n",
        "integers=tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)"
      ],
      "metadata": {
        "id": "boPmeRqasSEe",
        "outputId": "f6ef68d1-d0c2-4d5f-a95f-48062c672cb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><i>CREATING INPUT-TARGETT PAIRS</i></h3><br>\n",
        "\n",
        "we implement a dataloader that fetches the input-target pairs using a sliding window approach"
      ],
      "metadata": {
        "id": "FoEtjWFKyx2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"/content/drive/MyDrive/LLMDATA/the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text=f.read()\n",
        "enc_text=tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "id": "cAZPEEBisSA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffdf5107-bc9e-4c9c-a129-e1eac5b4e7f2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample=enc_text[50:]"
      ],
      "metadata": {
        "id": "KwJgtlM9sR7U"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size=4 #length of the input\n",
        "\"\"\"The context_size of 4 means that the model is trained to look at a sequence of 4 words tp predict the next word\n",
        "The input x is the first 4 tokens [1,2,3,4], and the target y is the next 4 tokens\"\"\"\n",
        "\n",
        "x=enc_sample[:context_size]\n",
        "y=enc_sample[1:context_size+1]\n",
        "\n",
        "print(f\"x:{x}\")\n",
        "print(f\"y:     {y}\")"
      ],
      "metadata": {
        "id": "Z-tvHOtUsR1u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0e0d71-a375-4ee8-98df-b2618b180a33"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:[290, 4920, 2241, 287]\n",
            "y:     [4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,context_size+1):\n",
        "  context=enc_sample[:i]\n",
        "  desired=enc_sample[i]\n",
        "  print (context,\"---->\",desired)"
      ],
      "metadata": {
        "id": "AsIKt_J9sRxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0c9209-6163-4d59-917f-063d005a4b25"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] ----> 4920\n",
            "[290, 4920] ----> 2241\n",
            "[290, 4920, 2241] ----> 287\n",
            "[290, 4920, 2241, 287] ----> 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.inputtransformer2 import TokenTransformBase\n",
        "for i in range(1,context_size+1):\n",
        "  context=enc_sample[:i]\n",
        "  desired=enc_sample[i]\n",
        "  print(tokenizer.decode(context),\"---->\", tokenizer.decode([desired]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryt15ry-wXXK",
        "outputId": "c25bc39a-be3d-4060-f46d-b7e7d06bd250"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and ---->  established\n",
            " and established ---->  himself\n",
            " and established himself ---->  in\n",
            " and established himself in ---->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "gSc4LerU6JST"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.input_ids=[]\n",
        "    self.target_ids=[]\n",
        "\n",
        "    token_ids=tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0,len(token_ids)-max_length,stride):\n",
        "      input_chunk=token_ids[i:i+max_length]\n",
        "      target_chunk=token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx],self.target_ids[idx]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CEnXzlepwXTc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt,batch_size=4,max_length=256,\n",
        "                         stride=128,shuffle=True,drop_last=True,\n",
        "                         num_workers=0):\n",
        "  tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset=GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
        "\n",
        "  dataloader=DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "h-lAd_t3wXPy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open (\"/content/drive/MyDrive/LLMDATA/the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text=f.read()"
      ],
      "metadata": {
        "id": "OjuDE3l-wW-2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pytorch version:\",torch.__version__)\n",
        "dataloader=create_dataloader_v1(\n",
        "    raw_text,batch_size=1,max_length=4,stride=1,shuffle=False\n",
        ")\n",
        "\n",
        "data_iter=iter(dataloader)\n",
        "first_batch=next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zltWbMDVwW7z",
        "outputId": "c335405a-094f-4b2f-d1b9-edf119d7cd45"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version: 2.9.0+cpu\n",
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch=next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg-CZgOXwW4g",
        "outputId": "1b1944db-a359-42bd-9aa1-b50e0569dbb4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader=create_dataloader_v1(raw_text,batch_size=8,max_length=4,stride=4,shuffle=False)\n",
        "\n",
        "data_iter=iter(dataloader)\n",
        "inputs,targets=next(data_iter)\n",
        "print(\"Inputs:\\n\",inputs)\n",
        "print(\"\\nTargets:\\n\",targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A96HS9kYwW1D",
        "outputId": "cdcb4d2c-797c-443b-a5b6-d6759025e1ea"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "r5woA8NS2taF",
        "outputId": "ffddbaa4-8291-4798-8462-6d0fe0c5bce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><i>Token Embeddings</i></h3>"
      ],
      "metadata": {
        "id": "KbLOTUt1JjuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "model=api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "-DIrYw5I2tWd",
        "outputId": "1640d7b3-106e-4c14-dd95-7ccaeb34652f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/LLMDATA/word2vec_google_news.model\")"
      ],
      "metadata": {
        "id": "mxvwcoIcKd_W"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load(\n",
        "    \"/content/drive/MyDrive/LLMDATA/word2vec_google_news.model\",\n",
        "    mmap='r'\n",
        ")\n"
      ],
      "metadata": {
        "id": "ine0-69RP3Ds"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors=model\n",
        "print(word_vectors['computer'])"
      ],
      "metadata": {
        "id": "_xgwWtRS2tS_",
        "outputId": "aae0590c-e749-4781-de62-13266cdb8327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
            " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
            "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
            "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
            " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
            " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
            "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
            "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
            " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
            " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
            " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
            "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
            " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
            "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
            "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
            "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
            " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
            " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
            "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
            "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
            "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
            "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
            " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
            " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
            "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
            "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
            " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
            "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
            " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
            " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
            " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
            " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
            "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
            " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
            "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
            "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
            " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
            " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
            " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
            " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
            " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
            " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
            " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
            " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
            "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
            " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
            "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
            "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
            " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
            "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
            " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
            "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
            " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
            " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
            " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
            " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
            " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
            " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
            " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
            "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
            "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
            " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
            "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
            " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
            "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
            " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
            "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
            " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
            " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
            " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
            "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
            "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
            "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
            "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
            "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pChI24302tOp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ima7KSjt2tKt"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}